# Generative AI with Large Language Models

Delve deep into the fascinating world of generative AI and learn how to apply it in real-world scenarios.

## Notebook Enhancement: Leveraging Local Resources for Model Training

**Announcement:** Empowering Local Model Training Capabilities

I am pleased to announce significant enhancements to my notebook, elevating its capabilities for AI research and development. These improvements now allow me to proficiently download and archive models locally, while also harnessing the substantial computational resources available on my local hardware.

The key upgrades implemented in my notebook are as follows:

- **Local Model Repository:** The capability to download and maintain models directly on my notebook significantly reduces dependency on external resources. This enhancement provides greater autonomy in model access.

- **Optimal Resource Utilization:** My notebook has been configured to leverage hardware; AMD Ryzen 5 5600G CPU and the NVIDIA GeForce RTX 3060 GPU, 12GB of VRAM.


## Course Overview

In this course, titled [Generative AI with LLMs](https://www.deeplearning.ai/courses/generative-ai-with-llms/), you will acquire a comprehensive understanding of generative AI and discover how to deploy it effectively in practical applications. By the end of this course, you will be equipped to:

- **Master Generative AI**: Gain profound insights into generative AI, from data collection and model selection to performance assessment and deployment.

- **Unleash the Power of Transformers**: Understand the inner workings of the transformer architecture that powers LLMs. Learn how these models are trained and how fine-tuning enables them to adapt to diverse use cases.

- **Optimize with Scaling Laws**: Employ empirical scaling laws to optimize model objectives across dataset size, computational resources, and inference needs.

- **Apply Cutting-Edge Techniques**: Utilize state-of-the-art training, fine-tuning, inference, tools, and deployment methodologies to maximize model performance within your project's specific constraints.

- **Navigate Business Challenges**: Explore the challenges and opportunities presented by generative AI in the business world through insights shared by industry experts.

The course is designed for developers with a solid foundation in LLMs, as well as a strong grasp of best practices for training and deployment. It will empower you to make informed decisions for your organization and rapidly prototype innovative solutions using this exciting technology.

## Course Breakdown

### Week 1: Generative AI Fundamentals

In the first week, you will delve into the fundamentals of generative AI, including the project lifecycle and model pre-training.

**Learning Objectives**:
- Explore the significance of model pre-training and the choice between continued pre-training and fine-tuning.
- Define key terms such as Generative AI, large language models, and transformer architecture.
- Understand the steps involved in an LLM-based generative AI model lifecycle.
- Address computational challenges during model pre-training and optimize memory usage.
- Examine scaling laws related to LLMs, covering aspects like dataset size, computational resources, and more.

[Lab 1 - Generative AI Use Case: Summarize Dialogue](https://github.com/DPR-droid/12_LLM_Cousera/blob/main/Lab_1_summarize_dialogue.ipynb)

## Week 1 Resources

### Week 2: Fine-Tuning and Model Evaluation

Week two focuses on fine-tuning LLMs and evaluating their performance using prompt datasets.

**Learning Objectives**:
- Discover how fine-tuning with instruction-based prompt datasets can enhance LLM performance on various tasks.
- Grasp the concept of catastrophic forgetting and methods to mitigate it.
- Learn about Parameter-efficient Fine Tuning (PEFT) and its role in reducing computational costs.
- Explore the advantages of fine-tuning with instruction-based prompt datasets for boosting LLM performance.
- Includes: 
- Save/Load the dataset to the local directory
- Save/Load the models and tokenizer to the local directory

## Week 2 Resources

[Lab 2 - Fine-tune a generative AI model for dialogue summarization](https://github.com/DPR-droid/12_LLM_Cousera/blob/main/Lab_2_fine_tune_generative_ai_model.ipynb)

### Week 3: Reinforcement Learning and Applications

The final week introduces reinforcement learning and its applications in LLM-powered systems.

**Learning Objectives**:
- Understand how Reinforcement Learning from Human Feedback (RLHF) leverages human input to enhance LLM performance and alignment.
- Examine the role of data collected from human labelers in training reward models for RLHF.
- Define chain-of-thought prompting and its use in enhancing LLM reasoning and planning abilities.
- Address challenges associated with LLMs' knowledge limitations and learn about information retrieval and augmentation techniques to overcome them.
- Includes: 
- Save/Load the dataset to the local directory
- Save/Load the models and tokenizer to the local directory

[Lab 3 - Fine-tune FLAN-T5 with reinforcement learning to generate more-positive summaries](https://github.com/DPR-droid/12_LLM_Cousera/blob/main/Lab_3_fine_tune_model_to_detoxify_summaries.ipynb)

## Week 3 Resources

## References
[Coursera - Generative AI with Large Language Models](https://www.coursera.org/learn/generative-ai-with-llms/)
